{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#概要\" data-toc-modified-id=\"概要-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>概要</a></span></li><li><span><a href=\"#2018-12-18\" data-toc-modified-id=\"2018-12-18-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2018-12-18</a></span><ul class=\"toc-item\"><li><span><a href=\"#検索組織の機械学習実行基盤-|-リクルートテクノロジーズ　メンバーズブログ\" data-toc-modified-id=\"検索組織の機械学習実行基盤-|-リクルートテクノロジーズ　メンバーズブログ-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>検索組織の機械学習実行基盤 | リクルートテクノロジーズ　メンバーズブログ</a></span><ul class=\"toc-item\"><li><span><a href=\"#登場キーワードについての調査\" data-toc-modified-id=\"登場キーワードについての調査-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>登場キーワードについての調査</a></span><ul class=\"toc-item\"><li><span><a href=\"#DRONE-:-CI/CD-のパイプライン処理\" data-toc-modified-id=\"DRONE-:-CI/CD-のパイプライン処理-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>DRONE : CI/CD のパイプライン処理</a></span></li><li><span><a href=\"#DigDag-:-機械学習処理システム向けのパイプライン処理ツール\" data-toc-modified-id=\"DigDag-:-機械学習処理システム向けのパイプライン処理ツール-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>DigDag : 機械学習処理システム向けのパイプライン処理ツール</a></span></li><li><span><a href=\"#.dig-ファイルのサンプル集\" data-toc-modified-id=\".dig-ファイルのサンプル集-2.1.1.3\"><span class=\"toc-item-num\">2.1.1.3&nbsp;&nbsp;</span>.dig ファイルのサンプル集</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#2018-12-19\" data-toc-modified-id=\"2018-12-19-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>2018-12-19</a></span><ul class=\"toc-item\"><li><span><a href=\"#機械学習プロジェクトが失敗する9つの理由---六本木で働くデータサイエンティストのブログ\" data-toc-modified-id=\"機械学習プロジェクトが失敗する9つの理由---六本木で働くデータサイエンティストのブログ-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>機械学習プロジェクトが失敗する9つの理由 - 六本木で働くデータサイエンティストのブログ</a></span><ul class=\"toc-item\"><li><span><a href=\"#ML-Ops-のポイント\" data-toc-modified-id=\"ML-Ops-のポイント-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>ML Ops のポイント</a></span></li><li><span><a href=\"#機械学習プロジェクトが失敗する理由\" data-toc-modified-id=\"機械学習プロジェクトが失敗する理由-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>機械学習プロジェクトが失敗する理由</a></span><ul class=\"toc-item\"><li><span><a href=\"#課題設定の誤り\" data-toc-modified-id=\"課題設定の誤り-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>課題設定の誤り</a></span></li><li><span><a href=\"#間違った問題に機械学習を使っている\" data-toc-modified-id=\"間違った問題に機械学習を使っている-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>間違った問題に機械学習を使っている</a></span></li><li><span><a href=\"#十分なデータがない\" data-toc-modified-id=\"十分なデータがない-3.1.2.3\"><span class=\"toc-item-num\">3.1.2.3&nbsp;&nbsp;</span>十分なデータがない</a></span></li><li><span><a href=\"#適切なデータがない（データのクオリティが低い）\" data-toc-modified-id=\"適切なデータがない（データのクオリティが低い）-3.1.2.4\"><span class=\"toc-item-num\">3.1.2.4&nbsp;&nbsp;</span>適切なデータがない（データのクオリティが低い）</a></span></li><li><span><a href=\"#(不要な）データが多すぎる\" data-toc-modified-id=\"(不要な）データが多すぎる-3.1.2.5\"><span class=\"toc-item-num\">3.1.2.5&nbsp;&nbsp;</span>(不要な）データが多すぎる</a></span></li><li><span><a href=\"#人材の配置が適材適所ではない\" data-toc-modified-id=\"人材の配置が適材適所ではない-3.1.2.6\"><span class=\"toc-item-num\">3.1.2.6&nbsp;&nbsp;</span>人材の配置が適材適所ではない</a></span></li><li><span><a href=\"#間違ったツールを使っている\" data-toc-modified-id=\"間違ったツールを使っている-3.1.2.7\"><span class=\"toc-item-num\">3.1.2.7&nbsp;&nbsp;</span>間違ったツールを使っている</a></span></li><li><span><a href=\"#適切なモデルを使っていない\" data-toc-modified-id=\"適切なモデルを使っていない-3.1.2.8\"><span class=\"toc-item-num\">3.1.2.8&nbsp;&nbsp;</span>適切なモデルを使っていない</a></span></li><li><span><a href=\"#適切な評価指標を使っていない\" data-toc-modified-id=\"適切な評価指標を使っていない-3.1.2.9\"><span class=\"toc-item-num\">3.1.2.9&nbsp;&nbsp;</span>適切な評価指標を使っていない</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "機械学習について調べた履歴を記録する。  \n",
    "Jupyter Notebook の便利な機能は、履歴作成に当たって大変助かる。(Table of Contents の自動生成など)\n",
    "まずは、細かい整理はせず、片っ端から記録するというスタイルで始めるとしよう。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-12-18\n",
    "\n",
    "## 検索組織の機械学習実行基盤 | リクルートテクノロジーズ　メンバーズブログ\n",
    "  https://recruit-tech.co.jp/blog/2018/09/10/qass_ml/\n",
    "  \n",
    "* 機械学習システムのアーキテクチャ図があるので参考になる。\n",
    "    * ![アーキテクチャ](https://s3-ap-northeast-1.amazonaws.com/prod-rtc-blog/wp-content/uploads/2018/08/31193348/flya.png)\n",
    "* ソフトウェア資産の再利用性を高めるため、Dockerを活用している。\n",
    "    * Google Container Registry (GCR)に、コンテナを登録している。\n",
    "* Google Kubernetes Engine (GKE)の上に、\"DRONE\", \"DigDag\" といったアプリケーションを構築。\n",
    "* 機械学習処理の最終出力は、Google Cloud Storage(GCS)上に保存。\n",
    "* 処理フローの共通化のポイント\n",
    "    1. モデル部分は共通化しているが、\n",
    "    2. 前処理部分は、サービスごとに開発する\n",
    "    \n",
    "### 登場キーワードについての調査\n",
    "\n",
    "#### DRONE : CI/CD のパイプライン処理\n",
    "\n",
    "JenkinsやCircle CIと同じカテゴリのCI/CDツールだが、**Gitイベント** をトリガーにして、**Dockerコンテナ**内部でジョブを実行することに特化したツールである。  \n",
    "Dockerを利用したマイクロサービス化が普及するにつれて、DRONEの普及も進んでいる模様。  \n",
    "\n",
    "1. 対象Gitリポジトリのルートディレクトリにある **.drone.yml** を読み込んで、パイプライン処理を実行する。\n",
    "   .drone.ymlの例\n",
    "   ***\n",
    "```\n",
    "pipeline:\n",
    "  # ステップは上から順に実行されます（順序付きmap）。\n",
    "  hello:\n",
    "    # ステップ毎にイメージを指定\n",
    "    image: alpine:3.6\n",
    "    # Dockerコンテナ起動時のエントリポイントとしてコマンドが実行されます。\n",
    "    # 各コマンドは同じシェルで実行されます。\n",
    "    commands:\n",
    "      - echo 　\"Hello World\"\n",
    "```\n",
    "   ***\n",
    "\n",
    "参照: https://engineering.linecorp.com/ja/blog/go-oss-ci-tool-drone-replaces-jenkins/\n",
    "\n",
    "\n",
    "#### DigDag : 機械学習処理システム向けのパイプライン処理ツール\n",
    "\n",
    "機械学習処理システムは、処理フローが複雑化しやすく（特に前処理）、技術的負債の利子が危険レベルになる傾向がある。  \n",
    "処理フローを記述しやすく、把握しやすく管理できるのがDigDagとのこと。  \n",
    "以下のように、処理フローを階層的に記述しやすい。\n",
    "\n",
    "![DigDag処理フローイメージ](http://docs.digdag.io/_images/grouping-tasks.png)\n",
    "\n",
    "\n",
    "yml的な記述をする .dig ファイルに処理フローの定義を記述する。\n",
    "\n",
    ".dig の例\n",
    "***\n",
    "```text\n",
    "# daily_etl.dig\n",
    "schedule:\n",
    "  daily>: 00:05:00\n",
    " \n",
    "+foo:\n",
    "  _retry: 3\n",
    " \n",
    "  +get_foo_metrics1:\n",
    "    sh>: SESSION_TIME=${session_time} python elasticsearch_client.py foo metrics1 1day > foo_metrics1_daily.csv\n",
    "  +vaidate_foo_metrics1:\n",
    "    sh>: bash data_validator.sh foo_metrics1_daily.csv\n",
    "  +commit_foo_metrics1:\n",
    "    sh>: bash commit.sh foo_metrics1_daily.csv\n",
    "  +get_foo_metrics2:\n",
    "    sh>: SESSION_TIME=${session_time} python elasticsearch_client.py foo metrics2 1day > foo_metrics2_daily.csv\n",
    "  +vaidate_foo_metrics2:\n",
    "    sh>: bash data_validator.sh foo_metrics2_daily.csv\n",
    "  +commit_foo_metrics2:\n",
    "    sh>: bash commit.sh foo_metrics2_daily.csv\n",
    "\n",
    "```\n",
    "***\n",
    "\n",
    "学習処理を定義する .dig ファイルの例を示す。\n",
    "***\n",
    "**daily_train.dig**\n",
    "```\n",
    "# daily_train.dig\n",
    "schedule:\n",
    "  daily>: 00:10:00\n",
    " \n",
    "+wait_daily_etl:\n",
    "  require>: daily_etl\n",
    " \n",
    "+foo:\n",
    "  +train:\n",
    "    _parallel: true\n",
    " \n",
    "    +train_foo_metrics1:\n",
    "      sh>: python train.py foo metrics1 foo_metrics1_daily.csv\n",
    "    +train_foo_metrics2:\n",
    "      sh>: python train.py foo metrics2 foo_metrics2_daily.csv\n",
    " \n",
    "  +cross_validation:\n",
    "    _pararell: true\n",
    " \n",
    "    +cross_validation_foo_metrics1:\n",
    "      sh>: python cross_validation.py foo metrics1\n",
    "    +cross_validation_foor_metrics2:\n",
    "      sh>: python cross_validation.py foo metrics2\n",
    " \n",
    "_error:\n",
    "  sh>: bash notify.sh\n",
    "```\n",
    "***\n",
    "\n",
    "cross_validation.py は、過学習を起こしていたと判断すると、終了コード 1 を返すプログラムとなっている。  \n",
    "過学習が起きると \\_error が呼び出され、通知処理(notify.sh)が起動するようになっている。  \n",
    "\n",
    "\n",
    "週次の処理をする場合は、以下のような依存関係を前提とした .digファイルを記述する。  \n",
    "以下の.digファイルは、 requireで指定された daily_train.dig が7回実行されるのを待ってから、foo 以下の処理が実行される。\n",
    "\n",
    "***\n",
    "```\n",
    "# fine_tuning.dig\n",
    "schedule:\n",
    "  weekly>: Mon,01:05:00\n",
    " \n",
    "+wait_daily_train:\n",
    "  loop>: 7\n",
    "  _do:\n",
    "    require>: daily_train\n",
    "    session_time: ${moment(last_session_time).add(i, 'day').format()}\n",
    " \n",
    "+foo:\n",
    "  +train:\n",
    "    _parallel: true\n",
    " \n",
    "    +fine_tuning_foo_metrics1:\n",
    "      sh>: python fine_tuning.py foo metrics1\n",
    "    +fine_tuning_foo_metrics2:\n",
    "      sh>: python fine_tuning.py foo metrics2\n",
    "```\n",
    "***\n",
    "\n",
    "\n",
    "定期的にポーリングして、モデルの性能悪化を検出したら、すかさず通知したいときには、以下のような .digファイルを作ると良いという。  \n",
    "以下では5分ごとに predict.py を実行し、モデルの性能が悪化して exit_code = 1 となったら、_error がキックされ、通知処理(notify.sh)が実行される\n",
    "。  \n",
    "\n",
    "*** \n",
    "```\n",
    "# predict.dig\n",
    "schedule:\n",
    "  minutes_interval>: 5\n",
    " \n",
    "+foo:\n",
    "  +predict:\n",
    "    _parallel: true\n",
    " \n",
    "    +predict_foo_metrics1:\n",
    "      sh>: python predict.py foo metrics1\n",
    "    +predict_foo_metrics2:\n",
    "      sh>: python predict.py foo metrics2\n",
    " \n",
    "_error:\n",
    "  sh>: bash notify.sh\n",
    "```\n",
    "***\n",
    "\n",
    "#### .dig ファイルのサンプル集\n",
    "\n",
    "トレジャーデータの以下のサイトで紹介している。  \n",
    "https://github.com/treasure-data/digdag/tree/master/examples\n",
    "\n",
    "##### 参照リンク\n",
    "* [DigDag公式サイト](http://docs.digdag.io/index.html)\n",
    "* https://www.lifull.blog/entry/2017/09/20/151600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-12-19\n",
    "\n",
    "## 機械学習プロジェクトが失敗する9つの理由 - 六本木で働くデータサイエンティストのブログ\n",
    "出展  https://tjo.hatenablog.com/entry/2018/08/03/080000\n",
    "\n",
    "### ML Ops のポイント\n",
    "\n",
    "DevOpsならぬ **\"ML Ops\"** が普及している。ML Ops で関心があるとされているのは以下の４点。  \n",
    "1. システムやサービスのどの場所で機械学習を使うのか\n",
    "2. 機械学習システムの運用方法のポイント\n",
    "    * 機械学習処理を含むコードのテスト方法\n",
    "    * 構築したモデルのデプロイ方法\n",
    "    * モデルとデータの監視\n",
    "        * 性能が悪化したことを検知して、モデル更新のタイミングを知らせる方法などか？\n",
    "    * 開発～デプロイプロセスの自動化の方法\n",
    "        * 先に触れたリクルートテクノロジーズのエントリーが該当するかもしれない\n",
    "3. 機械学習処理システムの高速化(ロジックのチューニングやGPUの利用など)\n",
    "4. 機械学習処理システムの開発体制,運用体制\n",
    "\n",
    "### 機械学習プロジェクトが失敗する理由\n",
    "\n",
    "#### 課題設定の誤り\n",
    "不正検知の場合、「過去に人が見つけてきた事例」をベースに不正を定義してしまうと、**「新しい手口の不正」**に対処できなくなってしまう。  \n",
    "この場合は、**「何が正常なのか」**を学習させるのが適切である。  \n",
    "異常時のデータが入手困難であれば、大量の正常データから、正常の定義をしっかりと構築し、そこから逸脱する異常値を検知するというわけである。  \n",
    "> 例えば「正常値データで学習させたAutoencoderで入力データを復元できたら正常値、復元できなかったら異常値」というやり方などは好例かと。\n",
    "\n",
    "#### 間違った問題に機械学習を使っている\n",
    "費用対効果を考慮せずに、闇雲に機械学習システムを作ると大変なことになる。  \n",
    "明確なニーズがあること(=機械学習を用いて解決するだけの**ビジネス的価値が高い問題**であること)を確かめずに、高いコストを払って機械学習システムを構築すると大赤字である。   \n",
    "> 「2000万円の人件費を浮かせるために1億円かけて機械学習システムを作ったのに、売上高はたったの3000万円」とかだと目も当てられません。\n",
    "\n",
    "#### 十分なデータがない\n",
    "そもそも**「データが入手困難/不可能な分野」**に、機械学習システムを投入することが戦略的に誤りである。  \n",
    "どんなに優秀な重火器（優秀なモデル）をそろえても、弾薬（データ）が無ければ戦うことはできない。\n",
    "\n",
    "\n",
    "#### 適切なデータがない（データのクオリティが低い）\n",
    "まさに**\"Garbage in, garbage out\"**。データの量はあるが、役に立たないか、誤ったデータばかりだと、モデルがいくら優秀でも誤った判断に収束してしまう。  \n",
    "データ有効性チェックプロセス(Data Validation Process)のための専任部署を立ち上げる企業もあるという。  \n",
    "ビジネス的価値の高い問題に取り組むのであれば、そうした専門部署を立ち上げても十分割に合うのではないか。\n",
    "\n",
    "#### (不要な）データが多すぎる\n",
    "データの量はあっても、手がかりとならないデータばかりだと苦労する。  \n",
    "「特徴量削減」の苦労である。  \n",
    "PCAやt-SNEで次元を圧縮するにせよ、特徴量を削減するにせよ、どの特徴量を残すのかは人の手にゆだねられる。  \n",
    "データを蓄積する段階から、機械学習にかけることを考慮した設計にしておくことが望ましい。  \n",
    "\n",
    "#### 人材の配置が適材適所ではない\n",
    "チームが小さい、部門の立ち上げ時期には、データ収集・加工・前処理・仮説検証・モデル構築・プロダクト実装・デプロイまで出来るオールマイティな古巣タックな機械学習開発者/データサイエンティストが数名いればよい。 \n",
    "\n",
    "だが、チームが大きくなってきたら、ETL特化型、モデル構築特化型など、機械学習分野の中でも特化した人材がいると良い。  \n",
    "データ基盤を世話するデータアーキテクトは、部門や事業の規模が大きくなってきたら必須になるだろう。  \n",
    "\n",
    "#### 間違ったツールを使っている\n",
    "レガシーな既存システムに縛られ、規模がスケールしにくい、従来の技術やシステムに固執するのは危険である。  \n",
    "将来、高い確率で**技術的負債**になる。  \n",
    "なるべく新しく、**スケールする技術**を取り入れるべきである。  \n",
    "* オンプレのデータベースよりは、クラウドのデータウェアハウス(GCPのBigQueryとか)\n",
    "\n",
    "#### 適切なモデルを使っていない\n",
    "闇雲にディープラーニングを導入するのは、問題である。適切なチューニングが出来ないと目も当てられなくなる。    \n",
    "例えば、線形分離可能な問題には線形モデルを適用すべきである。非線形モデルを入れるとおかしくなる。  \n",
    "機械学習モデルも適材適所である。\n",
    "\n",
    "#### 適切な評価指標を使っていない\n",
    "予測する対象、課題に応じて、重視する評価指標を使い分ける必要がある。  \n",
    "異常検知の場合、大多数が正常なので、精度(accuracy)で言えば常に１００％になってしまう。\n",
    "実際には、見逃すとリスクが大きいので、対象精度を犠牲にしてでも高い再現率(recall)を達成すべきケースが多いだろう。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
